I"i©<script type="text/javascript" async="" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>

<p>
<!--

<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">

<style>
    .share-box a {
  display: inline-block;
  -webkit-box-shadow: 0 0 1px #777;
  box-shadow: 0 0 1px #777;
  padding: 5px 12px;
  margin-right: 5px;
  margin-bottom: 5px;
  text-decoration: none; }
  .share-box a:hover {
    text-decoration: none;
    -webkit-transition: background-color 200ms linear;
    -ms-transition: background-color 200ms linear;
    transition: background-color 200ms linear; }

.f {
  color: #3b5998; }
  .f:hover {
    color: #fff;
    background-color: #3b5998; }

.t {
  color: #4099FF; }
  .t:hover {
    color: #fff;
    background-color: #4099FF; }

.g {
  color: #d34836; }
  .g:hover {
    color: #fff;
    background-color: #d34836; }

.r {
  color: #ff5700; }
  .r:hover {
    color: #fff;
    background-color: #ff5700; }

.l {
  color: #0077b5; }
  .l:hover {
    color: #fff;
    background-color: #0077b5; }

.e {
  color: #444444; }
  .e:hover {
    color: #fff;
    background-color: #444444; }
</style>

<div class="share-box">
<a class="f" href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/blog/linearreg.html" onclick="window.open(this.href, 'mywin',
'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" ><i class="fab fa-facebook-f"></i></a>

<a class="t" href="https://twitter.com/intent/tweet?text=&url=http://localhost:4000/blog/linearreg.html" onclick="window.open(this.href, 'mywin',
'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;"><i class="fab fa-twitter"></i></a>

  <a class="g" href="https://plus.google.com/share?url=http://localhost:4000/blog/linearreg.html" onclick="window.open(this.href, 'mywin',
'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" ><i class="fab fa-google-plus-square"></i></a>


<a class="r" href="http://www.reddit.com/submit?url=http://localhost:4000/blog/linearreg.html" onclick="window.open(this.href, 'mywin',
'left=20,top=20,width=900,height=500,toolbar=1,resizable=0'); return false;" ><i class="fab fa-reddit"></i></a>

<a class="l" href="https://www.linkedin.com/shareArticle?mini=true&url=http://localhost:4000/blog/linearreg.html" onclick="window.open(this.href, 'mywin',
'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" ><i class="fab fa-linkedin-in"></i></a>

<a class="e" href="mailto:?subject=&amp;body=Check out this site http://localhost:4000/blog/linearreg.html"><i class="fas fa-envelope-square"></i></a>
-->

  <!--
    <a href="https://twitter.com/renbedre?ref_src=twsrc%5Etfw" class="twitter-follow-button" data-show-count="false">Follow @renbedre</a><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
-->

<!--
</div>

-->

</p>

<h2 id="what-is-linear-regression-lr"><span style="color:#33a8ff">What is Linear Regression (LR)?</span></h2>
<ul>
  <li>Linear regression (LR) models the relationship between the explanatory/independent/predictor/regressor/exogeneous (X) variable with that
of dependent/response/criterion/endogeneous variable (Y)</li>
  <li>For example, how the likelihood of blood pressure is influenced by a personâ€™s age and weight. This relationship can 
be explained using linear regression</li>
  <li>In LR, the Y variable should be continuous whereas the X variable can be continuous or categorical. If both X and Y 
are continuous, the linear relationship can be estimated using correlation coefficient (r) or the coefficient of 
determination (r-squared)</li>
  <li>LR is useful if the relationships between the X and Y variables are linear</li>
  <li>LR is helpful to predict the value of Y based on the value of the X variable</li>
</ul>

<h2 id="types-of-linear-regression-lr"><span style="color:#33a8ff">Types of Linear Regression (LR)?</span></h2>
<ul>
  <li><u>Univariate LR</u>: Linear relationships between Y and X variables can be explained by single X variable</li>
</ul>

<p align="center">
  \( Y = a + bX + \epsilon \) <br />
  Where, a = y-intercept, b = slope of the regression line and \( \epsilon \) = error term (residuals)
  </p>

<ul>
  <li>
    <p><u>Multiple LR</u>: Linear relationships between Y and X variables can be explained by multiple X variables</p>

    <p align="center">
    \( Y = a + b_1X_1 + b_2X_2 + b_3X_3 + ... + b_nX_n + \epsilon \) <br />
    Where, a = y-intercept, b = slope of the regression line and \( \epsilon \) = error term (residuals)
    </p>
  </li>
  <li>The y-intercept (a) is a constant and slope (b) of regression line is a regression coefficient.</li>
  <li><a href="https://reneshbedre.github.io/blog/mlr.html" target="_blank">How to perform multiple linear regression?</a></li>
</ul>

<h2 id="linear-regression-lr-assumptions"><span style="color:#33a8ff">Linear Regression (LR) Assumptions</span></h2>
<ul>
  <li>Relationship between the X and Y variables should be linear</li>
  <li>Errors (residuals) should be independent of each other</li>
  <li>Errors (residuals) should be normally distributed with mean of 0</li>
  <li>Errors (residuals) should have equal variance (Homoscedasticity)</li>
</ul>

<h2 id="linear-regression-lr-outputs"><span style="color:#33a8ff">Linear Regression (LR) Outputs</span></h2>
<h3 id="correlation-coefficient-r">Correlation coefficient (r)</h3>
<ul>
  <li>r describes a linear relationship between X and Y variables</li>
  <li>r &gt; 0 indicates a positive linear relationship between X and Y variables. As one of the variable increases, the
other variable also increases. r = 1 is a perfect positive linear relationship</li>
  <li>Similarly, r &lt; 0 indicates a negative linear relationship between X and Y variables. As one of the variable increases, the
other variable decreases, and vice versa. r = -1 is perfect negative linear relationship</li>
  <li>r = 0 indicates, there is no linear relationship between the X and Y variables</li>
</ul>

<h3 id="coefficient-of-determination-r-squared">Coefficient of determination (r-squared)</h3>
<ul>
  <li>r-squared is a square of correlation coefficient (r) and usually represented as percentages</li>
  <li>r-squared explains the variation in the Y variable that is explained by the fitted regression line</li>
  <li>r-squared can range from 0 to 1 (0 to 100%). r-squared = 1 (100%) indicates that the fitted regression line
explains all the variability of Y variable around its mean.</li>
</ul>

<h3 id="residuals-regression-error">Residuals (regression error)</h3>
<ul>
  <li>Residuals or error in regression represents the distance of the observed data points from the
predicted regression line</li>
</ul>
<p align="center">
 \( residuals =  predicted \ Y \ (\hat{y}_i)  - actual \ Y (y_i) \)
 </p>

<h3 id="root-mean-square-error-rmse">Root Mean Square Error (RMSE)</h3>
<ul>
  <li>RMSE represents the standard deviation of the residuals. It gives an estimate of the spread of observed data points
across the predicted regression line</li>
</ul>

<h2 id="linear-regression-lr-in-python"><span style="color:#33a8ff">Linear Regression (LR) in Python</span></h2>
<ul>
  <li>We will use <code class="language-plaintext highlighter-rouge">bioinfokit v0.7.1</code> or later for performing LR.</li>
  <li>Check <a href="http://localhost:4000/blog/howtoinstall.html">How to install bioinfokit</a> for latest version.</li>
  <li>Download <a href="http://localhost:4000/assets/posts/reg/test_reg_uni.csv">dataset</a></li>
</ul>

<h3 id="perform-linear-regression-lr">Perform Linear Regression (LR)</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># you can use interactive python interpreter, jupyter notebook, google colab, spyder or python code
# I am using interactive python interpreter (Python 3.8.2)
</span><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">bioinfokit.analys</span> <span class="kn">import</span> <span class="n">stat</span><span class="p">,</span> <span class="n">get_data</span>
<span class="c1"># load dataset as pandas dataframe
# should not have missing values (NaN)
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s">'slr'</span><span class="p">).</span><span class="n">data</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
   <span class="n">X1</span>    <span class="n">Y</span>
<span class="mi">0</span>  <span class="mi">25</span>  <span class="mi">670</span>
<span class="mi">1</span>  <span class="mi">30</span>  <span class="mi">690</span>
<span class="mi">2</span>  <span class="mi">18</span>  <span class="mi">635</span>
<span class="mi">3</span>  <span class="mi">15</span>  <span class="mi">625</span>
<span class="mi">4</span>  <span class="mi">20</span>  <span class="mi">640</span>

<span class="c1"># LR with one independent variable
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span><span class="o">=</span> <span class="n">stat</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span><span class="p">.</span><span class="n">lin_reg</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="p">[</span><span class="s">"X1"</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="p">[</span><span class="s">"Y"</span><span class="p">])</span>

<span class="c1"># output
</span><span class="n">Regression</span> <span class="n">equation</span><span class="p">:</span>

<span class="mf">569.0916</span> <span class="o">+</span> <span class="p">(</span><span class="mf">3.7515</span><span class="o">*</span><span class="n">X1</span><span class="p">)</span>

<span class="n">Regression</span> <span class="n">Summary</span><span class="p">:</span>


<span class="o">----------------------------------------</span>  <span class="o">--------</span>
<span class="n">Dependent</span> <span class="n">variables</span>                       <span class="p">[</span><span class="s">'X1'</span><span class="p">]</span>
<span class="n">Independent</span> <span class="n">variables</span>                     <span class="p">[</span><span class="s">'Y'</span><span class="p">]</span>
<span class="n">Coefficient</span> <span class="n">of</span> <span class="n">determination</span> <span class="p">(</span><span class="n">r</span><span class="o">-</span><span class="n">squared</span><span class="p">)</span>  <span class="mf">0.918</span>
<span class="n">Adjusted</span> <span class="n">r</span><span class="o">-</span><span class="n">squared</span>                        <span class="mf">0.9141</span>
<span class="n">Root</span> <span class="n">Mean</span> <span class="n">Square</span> <span class="n">Error</span> <span class="p">(</span><span class="n">RMSE</span><span class="p">)</span>             <span class="mf">6.6718</span>
<span class="n">Mean</span> <span class="n">of</span> <span class="n">Y</span>                                 <span class="mf">639.3913</span>
<span class="n">Residual</span> <span class="n">standard</span> <span class="n">error</span>                   <span class="mf">6.9808</span>
<span class="n">No</span><span class="p">.</span> <span class="n">of</span> <span class="n">Observations</span>                       <span class="mi">23</span>

<span class="n">Regression</span> <span class="n">Coefficients</span><span class="p">:</span>

<span class="n">Parameter</span>      <span class="n">Estimate</span>    <span class="n">Std</span> <span class="n">Error</span>    <span class="n">t</span><span class="o">-</span><span class="n">value</span>    <span class="n">P</span><span class="o">-</span><span class="n">value</span> <span class="n">Pr</span><span class="p">(</span><span class="o">&gt;|</span><span class="n">t</span><span class="o">|</span><span class="p">)</span>
<span class="o">-----------</span>  <span class="o">----------</span>  <span class="o">-----------</span>  <span class="o">---------</span>  <span class="o">------------------</span>
<span class="n">Intercept</span>     <span class="mf">569.092</span>         <span class="mf">4.8094</span>   <span class="mf">118.329</span>           <span class="mf">3.7802e-31</span>
<span class="n">X1</span>              <span class="mf">3.75149</span>       <span class="mf">0.2446</span>    <span class="mf">15.3373</span>          <span class="mf">7.0019e-13</span>


<span class="n">ANOVA</span> <span class="n">Summary</span><span class="p">:</span>

<span class="n">Source</span>      <span class="n">Df</span>    <span class="n">Sum</span> <span class="n">Squares</span>  <span class="n">Mean</span> <span class="n">Squares</span>    <span class="n">F</span>         <span class="n">Pr</span><span class="p">(</span><span class="o">&gt;</span><span class="n">F</span><span class="p">)</span>
<span class="o">--------</span>  <span class="o">----</span>  <span class="o">-------------</span>  <span class="o">--------------</span>  <span class="o">--------</span>  <span class="o">----------</span>
<span class="n">Model</span>        <span class="mi">1</span>       <span class="mf">11462.1</span>   <span class="mf">11462.1214</span>      <span class="mf">235.2108</span>  <span class="mf">7.0080E-13</span>
<span class="n">Error</span>       <span class="mi">21</span>        <span class="mf">1023.36</span>  <span class="mf">48.7313</span>
<span class="n">Total</span>       <span class="mi">22</span>       <span class="mf">12485.5</span>

<span class="c1"># you can check predicted response (y_hat)
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">reg</span><span class="p">.</span><span class="n">y_hat</span>
</code></pre></div></div>
<h3 id="interpretation">Interpretation</h3>
<ul>
  <li>The regression line with equation [Y = 569.0916 + (3.7515*X1)], is helpful to predict the value of the Y variable 
from the given value of the X1 variable. In general, a regression can be useful in predicting the Y of any value 
within the range of X1. It can be also used to predict Y from X outside the given range, but such extrapolation may 
not be useful</li>
  <li>The slope (3.7515) represents the change in the Y per unit change in the X1 variable. It means that the value Y 
increases by 3.7515 with each unit increase in X1</li>
  <li>The intercept (569.0916) represents the value of Y at X1 = 0. Here need to be cautious to interpret intercept as 
sometimes the value (X1=0) does not make any sense (e.g. speed of car or height of the person). In such cases, the 
values within the range of X1 should be considered to interpret the intercept</li>
  <li>The coefficient of determination (r-squared) is 0.918 (91.8%), which suggests that 91.8% of the variance in Y can be 
explained by X1 alone. Adjusted r-squared is useful where there are multiple X variables in the model (multiple 
linear regression)</li>
  <li>The correlation coefficient (r) is 0.9581, which suggests that there is a positive relationship between X and Y 
variables. As X1 increases, Y also increases</li>
  <li>From Regression Coefficients, the P-value obtained for X1 independent variable is significant (&lt;0.05), it suggests 
that X1 significantly influence the response variable Y (there is a significant relationship between X1 and Y)</li>
  <li>From ANOVA, the P-value is significant (&lt;0.05), which suggests that there is a significant relationship between X1 and Y.
The X1 variable can reliably predict the Y variable.</li>
</ul>

<h3 id="linear-regression-lr-plot">Linear Regression (LR) plot</h3>

<p>Generate regression plot,</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">bioinfokit</span> <span class="kn">import</span> <span class="n">visuz</span>
<span class="c1"># get predicted Y and add to original dataframe
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">df</span><span class="p">[</span><span class="s">'yhat'</span><span class="p">]</span><span class="o">=</span><span class="n">reg</span><span class="p">.</span><span class="n">y_hat</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
   <span class="n">X1</span>    <span class="n">Y</span>        <span class="n">yhat</span>
<span class="mi">0</span>  <span class="mi">25</span>  <span class="mi">670</span>  <span class="mf">662.878924</span>
<span class="mi">1</span>  <span class="mi">30</span>  <span class="mi">690</span>  <span class="mf">681.636398</span>
<span class="mi">2</span>  <span class="mi">18</span>  <span class="mi">635</span>  <span class="mf">636.618460</span>
<span class="mi">3</span>  <span class="mi">15</span>  <span class="mi">625</span>  <span class="mf">625.363976</span>
<span class="mi">4</span>  <span class="mi">20</span>  <span class="mi">640</span>  <span class="mf">644.121450</span>

<span class="c1"># create regression plot with defaults
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">visuz</span><span class="p">.</span><span class="n">stat</span><span class="p">.</span><span class="n">regplot</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">'X1'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'Y'</span><span class="p">,</span> <span class="n">yhat</span><span class="o">=</span><span class="s">'yhat'</span><span class="p">)</span>
<span class="c1"># plot will be saved in same dir (reg_plot.png)
# set parameter show=True, if you want view the image instead of saving
</span></code></pre></div></div>
<p align="center">
<img src="/assets/posts/reg/reg_plot.png" width="600" />
</p>

<h3 id="check-linear-regression-lr-assumptions">Check Linear Regression (LR) Assumptions</h3>

<p><u>Residuals vs fitted (y_hat) plot</u>: This plot used to check for linearity, variances and outliers in
the regression data</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># get residuals and standardized residuals and add to original dataframe
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">df</span><span class="p">[</span><span class="s">'res'</span><span class="p">]</span><span class="o">=</span><span class="n">reg</span><span class="p">.</span><span class="n">residuals</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">df</span><span class="p">[</span><span class="s">'std_res'</span><span class="p">]</span><span class="o">=</span><span class="n">reg</span><span class="p">.</span><span class="n">std_residuals</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
   <span class="n">X1</span>    <span class="n">Y</span>        <span class="n">yhat</span>       <span class="n">res</span>   <span class="n">std_res</span>
<span class="mi">0</span>  <span class="mi">25</span>  <span class="mi">670</span>  <span class="mf">662.878924</span>  <span class="mf">7.121076</span>  <span class="mf">1.017297</span>
<span class="mi">1</span>  <span class="mi">30</span>  <span class="mi">690</span>  <span class="mf">681.636398</span>  <span class="mf">8.363602</span>  <span class="mf">1.194800</span>
<span class="mi">2</span>  <span class="mi">18</span>  <span class="mi">635</span>  <span class="mf">636.618460</span> <span class="o">-</span><span class="mf">1.618460</span> <span class="o">-</span><span class="mf">0.231209</span>
<span class="mi">3</span>  <span class="mi">15</span>  <span class="mi">625</span>  <span class="mf">625.363976</span> <span class="o">-</span><span class="mf">0.363976</span> <span class="o">-</span><span class="mf">0.051997</span>
<span class="mi">4</span>  <span class="mi">20</span>  <span class="mi">640</span>  <span class="mf">644.121450</span> <span class="o">-</span><span class="mf">4.121450</span> <span class="o">-</span><span class="mf">0.588779</span>

<span class="c1"># create fitted (y_hat) vs residuals plot
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">visuz</span><span class="p">.</span><span class="n">stat</span><span class="p">.</span><span class="n">reg_resid_plot</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">yhat</span><span class="o">=</span><span class="s">'yhat'</span><span class="p">,</span> <span class="n">resid</span><span class="o">=</span><span class="s">'res'</span><span class="p">,</span> <span class="n">stdresid</span><span class="o">=</span><span class="s">'std_res'</span><span class="p">)</span>
<span class="c1"># plot will be saved in same dir (resid_plot.png and std_resid_plot.png)
# set parameter show=True, if you want view the image instead of saving
</span></code></pre></div></div>
<p align="center">
<img src="/assets/posts/reg/resid_plot.png" width="500" />
<img src="/assets/posts/reg/std_resid_plot.png" width="500" />
</p>

<p>From the plot,</p>
<ul>
  <li>As the data is pretty equally distributed around the line=0 in the residual plot, it meets the assumption of residual 
equal variances. The outliers could be detected here if the data lies far away from the line=0.</li>
  <li>In the standardized residual plot, the residuals are within -2 and +2 range and suggest that it meets assumptions of 
linearity</li>
</ul>

<p><u>Quantile-quantile (QQ) plot</u>: This plot used to check the data normality assumption</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># you can use interactive python interpreter, jupyter notebook, spyder or python code
# I am using interactive python interpreter (Python 3.7)
</span><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="n">sm</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="c1"># check dataframe for required variables (we will need std_res variable for QQ plot)
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
   <span class="n">X1</span>    <span class="n">Y</span>        <span class="n">yhat</span>       <span class="n">res</span>   <span class="n">std_res</span>
<span class="mi">0</span>  <span class="mi">25</span>  <span class="mi">670</span>  <span class="mf">662.878924</span>  <span class="mf">7.121076</span>  <span class="mf">1.017297</span>
<span class="mi">1</span>  <span class="mi">30</span>  <span class="mi">690</span>  <span class="mf">681.636398</span>  <span class="mf">8.363602</span>  <span class="mf">1.194800</span>
<span class="mi">2</span>  <span class="mi">18</span>  <span class="mi">635</span>  <span class="mf">636.618460</span> <span class="o">-</span><span class="mf">1.618460</span> <span class="o">-</span><span class="mf">0.231209</span>
<span class="mi">3</span>  <span class="mi">15</span>  <span class="mi">625</span>  <span class="mf">625.363976</span> <span class="o">-</span><span class="mf">0.363976</span> <span class="o">-</span><span class="mf">0.051997</span>
<span class="mi">4</span>  <span class="mi">20</span>  <span class="mi">640</span>  <span class="mf">644.121450</span> <span class="o">-</span><span class="mf">4.121450</span> <span class="o">-</span><span class="mf">0.588779</span>

<span class="c1"># create QQ plot
# line=45 option to plot the data around 45 degree line
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">sm</span><span class="p">.</span><span class="n">qqplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'std_res'</span><span class="p">],</span> <span class="n">line</span><span class="o">=</span><span class="s">'45'</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Theoretical Quantiles"</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Standardized Residuals"</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>

</code></pre></div></div>
<p align="center">
<img src="/assets/posts/reg/qqplot.png" width="600" />
</p>

<p>From the plot,</p>
<ul>
  <li>As the standardized residuals lie around the 45-degree line, it suggests that the residuals are normally distributed</li>
</ul>

<p>Check for <a href="https://reneshbedre.github.io/blog/mlr.html" target="_blank">How to perform multiple linear regression?</a></p>

<h2 id="linear-regression-with-pytorch">Linear Regression with PyTorch</h2>

<p>Letâ€™s perform a LR with PyTorch with the same dataset</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">bioinfokit.analys</span> <span class="kn">import</span> <span class="n">stat</span><span class="p">,</span> <span class="n">get_data</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="n">th</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s">'slr'</span><span class="p">).</span><span class="n">data</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
   <span class="n">X1</span>    <span class="n">Y</span>
<span class="mi">0</span>  <span class="mi">25</span>  <span class="mi">670</span>
<span class="mi">1</span>  <span class="mi">30</span>  <span class="mi">690</span>
<span class="mi">2</span>  <span class="mi">18</span>  <span class="mi">635</span>
<span class="mi">3</span>  <span class="mi">15</span>  <span class="mi">625</span>
<span class="mi">4</span>  <span class="mi">20</span>  <span class="mi">640</span>

<span class="c1"># convert to PyTorch tensor 
# variable shape should be (samples, features)
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">X1</span> <span class="o">=</span> <span class="n">th</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">df</span><span class="p">[[</span><span class="s">'X1'</span><span class="p">]].</span><span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">th</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">th</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">df</span><span class="p">[[</span><span class="s">'Y'</span><span class="p">]].</span><span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">th</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># LR model using PyTorch
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">in_features</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># number of independent variable
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">out_features</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># dim of predicted variable
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">lr_model</span> <span class="o">=</span> <span class="n">th</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">)</span>

<span class="c1"># define loss function (regression error)
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">mse_loss</span> <span class="o">=</span> <span class="n">th</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">MSELoss</span><span class="p">()</span>
<span class="c1"># optimize to minimize the loss function and find optimal LR parameters (Regression Coefficients)
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">optimizer</span> <span class="o">=</span> <span class="n">th</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr_model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.002</span><span class="p">)</span>  
<span class="c1"># set number of iterations until you see the convergence in the loss function
# when you see similar minimum values for a large number of ending iterations
# it will give you the best values of LR parameters
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">n_iter</span> <span class="o">=</span> <span class="mi">20000</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_iter</span><span class="p">):</span>
        <span class="c1"># predict model with current LR parameters
</span>        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">lr_model</span><span class="p">(</span><span class="n">X1</span><span class="p">)</span>
        <span class="c1"># calculate loss function
</span>        <span class="n">step_loss</span> <span class="o">=</span> <span class="n">mse_loss</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
        
        <span class="c1"># Backward to find the derivatives of the loss function with respect to LR parameters
</span>        <span class="c1"># make any stored gradients to zero
</span>        <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">step_loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="c1"># update with current step LR parameters 
</span>        <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
        
        <span class="k">print</span> <span class="p">(</span><span class="s">'i [{}], Loss: {:.2f}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">step_loss</span><span class="p">.</span><span class="n">item</span><span class="p">()))</span>

<span class="c1"># see the last few iterations
</span><span class="n">i</span> <span class="p">[</span><span class="mi">19986</span><span class="p">],</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">44.51</span>
<span class="n">i</span> <span class="p">[</span><span class="mi">19987</span><span class="p">],</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">44.51</span>
<span class="n">i</span> <span class="p">[</span><span class="mi">19988</span><span class="p">],</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">44.51</span>
<span class="n">i</span> <span class="p">[</span><span class="mi">19989</span><span class="p">],</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">44.51</span>
<span class="n">i</span> <span class="p">[</span><span class="mi">19990</span><span class="p">],</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">44.51</span>
<span class="n">i</span> <span class="p">[</span><span class="mi">19991</span><span class="p">],</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">44.51</span>
<span class="n">i</span> <span class="p">[</span><span class="mi">19992</span><span class="p">],</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">44.51</span>
<span class="n">i</span> <span class="p">[</span><span class="mi">19993</span><span class="p">],</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">44.51</span>
<span class="n">i</span> <span class="p">[</span><span class="mi">19994</span><span class="p">],</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">44.51</span>
<span class="n">i</span> <span class="p">[</span><span class="mi">19995</span><span class="p">],</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">44.51</span>
<span class="n">i</span> <span class="p">[</span><span class="mi">19996</span><span class="p">],</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">44.51</span>
<span class="n">i</span> <span class="p">[</span><span class="mi">19997</span><span class="p">],</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">44.51</span>
<span class="n">i</span> <span class="p">[</span><span class="mi">19998</span><span class="p">],</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">44.51</span>
<span class="n">i</span> <span class="p">[</span><span class="mi">19999</span><span class="p">],</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">44.51</span>
</code></pre></div></div>

<p>Now, get the best LR parameters from this trained model,</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># intercept (a)
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">lr_model</span><span class="p">.</span><span class="n">bias</span><span class="p">.</span><span class="n">item</span><span class="p">()</span>
<span class="mf">568.7089233398438</span>
<span class="c1"># slope (b)
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">lr_model</span><span class="p">.</span><span class="n">weight</span><span class="p">.</span><span class="n">item</span><span class="p">()</span>
<span class="mf">3.7700467109680176</span>
</code></pre></div></div>

<p>Generate regression plot,</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">bioinfokit.visuz</span> <span class="kn">import</span> <span class="n">stat</span>
<span class="c1"># detach will not build a gradient computational graph (no backpropagation) 
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">lr_model</span><span class="p">(</span><span class="n">X1</span><span class="p">).</span><span class="n">detach</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">df</span><span class="p">[</span><span class="s">'yhat'</span><span class="p">]</span><span class="o">=</span><span class="n">y_pred</span><span class="p">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">stat</span><span class="p">.</span><span class="n">regplot</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">'X1'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'Y'</span><span class="p">,</span> <span class="n">yhat</span><span class="o">=</span><span class="s">'yhat'</span><span class="p">)</span>
</code></pre></div></div>

<p align="center">
<img src="/assets/posts/reg/reg_plot_pytorch.svg" width="600" />
</p>

<p>Now, letâ€™s predict the Y from some random X1,</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">X1_data</span> <span class="o">=</span> <span class="mi">28</span>
<span class="c1"># predict Y value when X1 is 28
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">lr_model</span><span class="p">(</span><span class="n">th</span><span class="p">.</span><span class="n">tensor</span><span class="p">([[</span><span class="n">X1_data</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">th</span><span class="p">.</span><span class="n">float32</span><span class="p">)).</span><span class="n">detach</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_pred</span><span class="p">.</span><span class="n">item</span><span class="p">()</span>
<span class="mf">674.2701416015625</span>
<span class="c1"># Y=674.27 when X1 is 28
</span></code></pre></div></div>

<p>
<strong style="color:#33a8ff">How to cite?</strong>
<br />
Renesh Bedre.(2020, July 29). reneshbedre/bioinfokit: Bioinformatics data analysis and visualization toolkit (Version v0.9). Zenodo.
<a href="http://doi.org/10.5281/zenodo.3965241" target="_blank">http://doi.org/10.5281/zenodo.3965241</a>
<br /><br />
<span style="color:#9e9696">If you have any questions, comments or recommendations, please email me at
<b>reneshbe@gmail.com</b></span>





<!-- Begin Mailchimp Signup Form -->

<!--
<link href="//cdn-images.mailchimp.com/embedcode/horizontal-slim-10_7.css" rel="stylesheet" type="text/css">
<style type="text/css">
	#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; width:100%;}
	/* Add your own Mailchimp form style overrides in your site stylesheet or in this style block.
	   We recommend moving this block and the preceding CSS link to the HEAD of your HTML file. */
</style>
<div id="mc_embed_signup">
<form action="https://github.us10.list-manage.com/subscribe/post?u=1c0202ed60d33515742eec50a&amp;id=b17e2351b6" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
    <div id="mc_embed_signup_scroll">
	<label for="mce-EMAIL">Subscribe for new articles</label>
	<input type="email" value="" name="EMAIL" class="email" id="mce-EMAIL" placeholder="email address" required>
-->

    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
<!--
<div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_1c0202ed60d33515742eec50a_b17e2351b6" tabindex="-1" value=""></div>
    <div class="clear"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
    </div>
</form>
</div>
-->

<!--End mc_embed_signup-->
</p>

<p>
<!--

<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">

<style>
    .share-box a {
  display: inline-block;
  -webkit-box-shadow: 0 0 1px #777;
  box-shadow: 0 0 1px #777;
  padding: 5px 12px;
  margin-right: 5px;
  margin-bottom: 5px;
  text-decoration: none; }
  .share-box a:hover {
    text-decoration: none;
    -webkit-transition: background-color 200ms linear;
    -ms-transition: background-color 200ms linear;
    transition: background-color 200ms linear; }

.f {
  color: #3b5998; }
  .f:hover {
    color: #fff;
    background-color: #3b5998; }

.t {
  color: #4099FF; }
  .t:hover {
    color: #fff;
    background-color: #4099FF; }

.g {
  color: #d34836; }
  .g:hover {
    color: #fff;
    background-color: #d34836; }

.r {
  color: #ff5700; }
  .r:hover {
    color: #fff;
    background-color: #ff5700; }

.l {
  color: #0077b5; }
  .l:hover {
    color: #fff;
    background-color: #0077b5; }

.e {
  color: #444444; }
  .e:hover {
    color: #fff;
    background-color: #444444; }
</style>

<div class="share-box">
<a class="f" href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/blog/linearreg.html" onclick="window.open(this.href, 'mywin',
'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" ><i class="fab fa-facebook-f"></i></a>

<a class="t" href="https://twitter.com/intent/tweet?text=&url=http://localhost:4000/blog/linearreg.html" onclick="window.open(this.href, 'mywin',
'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;"><i class="fab fa-twitter"></i></a>

  <a class="g" href="https://plus.google.com/share?url=http://localhost:4000/blog/linearreg.html" onclick="window.open(this.href, 'mywin',
'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" ><i class="fab fa-google-plus-square"></i></a>


<a class="r" href="http://www.reddit.com/submit?url=http://localhost:4000/blog/linearreg.html" onclick="window.open(this.href, 'mywin',
'left=20,top=20,width=900,height=500,toolbar=1,resizable=0'); return false;" ><i class="fab fa-reddit"></i></a>

<a class="l" href="https://www.linkedin.com/shareArticle?mini=true&url=http://localhost:4000/blog/linearreg.html" onclick="window.open(this.href, 'mywin',
'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" ><i class="fab fa-linkedin-in"></i></a>

<a class="e" href="mailto:?subject=&amp;body=Check out this site http://localhost:4000/blog/linearreg.html"><i class="fas fa-envelope-square"></i></a>
-->

  <!--
    <a href="https://twitter.com/renbedre?ref_src=twsrc%5Etfw" class="twitter-follow-button" data-show-count="false">Follow @renbedre</a><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
-->

<!--
</div>

-->

</p>

<p><span style="color:#9e9696"><i> Last updated: July 12, 2020</i> </span></p>

<p>
<a rel="license" href="http://creativecommons.org/licenses/by/4.0/" target="_blank"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/" target="_blank">Creative Commons Attribution 4.0 International License</a>.
</p>
:ET